{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZSL Blog Post.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoMVvIRtMXmY",
        "colab_type": "text"
      },
      "source": [
        "# An Overview of Zero Shot Learning in NLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aILhOF60WcIm",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC04NtlJWgyh",
        "colab_type": "text"
      },
      "source": [
        "## History of ZSL and its meaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J247sQEQsF0u",
        "colab_type": "text"
      },
      "source": [
        "## Methods and Uses in NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT4PG_Otsdlt",
        "colab_type": "text"
      },
      "source": [
        "### \"Zero-shot\" as an Evaluation Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB9T-krfQ9Ip",
        "colab_type": "text"
      },
      "source": [
        "### A ready-made, actually useful ZSL classifier\n",
        "\n",
        "Recently, [Yin et al.](https://arxiv.org/abs/1909.00161) proposed a method which uses a pre-trained MNLI sequence-pair classifier as an out-of-the-box zero-shot text classifier that actually works pretty well.\n",
        "\n",
        "As some quick background, Natural Language Inference (NLI) considers two sentences: a \"premise\" and a \"hypothesis\". The task is to determine whether the hypothesis is true (entailment) or false (contradiction) given the premise.\n",
        "\n",
        "![example NLI sentences](https://i.ibb.co/gWCjvdP/Screen-Shot-2020-05-26-at-5-10-07-PM.png \"NLI Examples from [NLP Progress](http://nlpprogress.com/english/natural_language_inference.html)\")\n",
        "\n",
        "The idea is to take the sequence we're interested in labeling as the \"premise\" and to turn each candidate label into a \"hypothesis.\" If the model says that the premise \"entails\" the hypothesis, we take the label to be true. This gives us a ready-made compatibility function that works reasonably well on certain tasks without any task-specific training. See the code snippet below to see how easily this can be done with ðŸ¤— Transformers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La_ga8KvSFYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "274cdb48-a518-4cee-c031-e27947e9a7ed"
      },
      "source": [
        "#collapse-show\n",
        "# load model pretrained on MNLI\n",
        "from transformers import BartForSequenceClassification, BartTokenizer\n",
        "tokenizer = BartTokenizer.from_pretrained('bart-large-mnli')\n",
        "model = BartForSequenceClassification.from_pretrained('bart-large-mnli')\n",
        "\n",
        "# pose sequence as a NLI premise and label (politics) as a hypothesis\n",
        "premise = 'Who are you voting for in 2020?'\n",
        "hypothesis = 'This text is about politics.'\n",
        "\n",
        "# run through model pre-trained on MNLI\n",
        "input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
        "logits = model(input_ids)[0]\n",
        "\n",
        "# we throw away \"neutral\" (dim 1) and take the probability of\n",
        "# \"entailment\" (2) as the probability of the label being true \n",
        "entail_contradiction_logits = logits[:,[0,2]]\n",
        "probs = entail_contradiction_logits.softmax(dim=1)\n",
        "true_prob = probs[:,1].item() * 100\n",
        "print(f'Probability that the label is true: {true_prob:0.2f}%')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability that the label is true: 99.04%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwXSg464flMJ",
        "colab_type": "text"
      },
      "source": [
        "In the paper, the authors report an F1 of $37.9$ on Yahoo Answers using the smallest version of BERT fine-tuned only on the Multi-genre NLI (MNLI) corpus. By simply using the larger and more recent Bart model pre-trained on MNLI, we were able to bring this number up to $53.7$. For context, Yahoo Answers has 10 classes and [supervised models](https://paperswithcode.com/sota/text-classification-on-yahoo-answers) get an accuracy of just over $70\\%$.\n",
        "\n",
        "Of course, this number can be improved when some data is available for training. In addition to the extreme fully unsupervised setting, the authors consider a setup which corresponds to the traditional _generalized zero-shot learning_ setting where only a subset of the dataset's labels are available during training. The model is then evaluated on all labels together, both seen and unseen, at test time.\n",
        "\n",
        "See [our live demo here](http://35.208.71.201:8000/) to try it out for yourself! Enter a sequence you want to classify and any labels of interest and watch Bart do its magic in real time.\n",
        "\n",
        "![live demo](https://i.ibb.co/WB6HsFk/Screen-Shot-2020-05-26-at-5-31-25-PM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4-AWozPs5On",
        "colab_type": "text"
      },
      "source": [
        "#### Sections to put somewhere:\n",
        "- Zero-shot learning and its relationship to few-shot learning, sample efficiency, domain adaptation\n",
        "- Some kind of good visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6T6rRDBuKkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}