{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZSL Blog Post.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoMVvIRtMXmY",
        "colab_type": "text"
      },
      "source": [
        "# An Overview of Zero Shot Learning in NLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB9T-krfQ9Ip",
        "colab_type": "text"
      },
      "source": [
        "### A Ready-made Zero-Shot Text Classifier with ðŸ¤— Transformers\n",
        "\n",
        "At EMNLP last year, [Yin et al.](https://dx.doi.org/10.18653/v1/d19-1404) proposed a method which uses a pre-trained MNLI sequence-pair classifier as an out-of-the-box text/label compatibility function.\n",
        "\n",
        "The idea is to take the sequence as the \"premise\" and turn each possible label of interest into a \"hypothesis.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La_ga8KvSFYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#collapse-show\n",
        "# load model pretrained on MNLI\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bart-large-mnli')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bart-large-mnli')\n",
        "\n",
        "# pose sequence as a NLI premise and label (politics) as a hypothesis\n",
        "premise = \"Who are you voting for in 2020?\"\n",
        "hypothesis = f'This text is about politics.'\n",
        "\n",
        "# run through model pre-trained on MNLI\n",
        "input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
        "logits = model(input_ids)[0]\n",
        "\n",
        "# we throw away \"neutral\" (dim 1) and take the probability of\n",
        "# \"entailment\" (2) as the probability of the label being true \n",
        "entail_contradiction_logits = logits[:,[0,2]]\n",
        "probs = entail_contradiction_logits.softmax(1)\n",
        "true_prob = probs[:,1].item() * 100\n",
        "print(f'Probability that the label is true: {true_prob:0.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NrG8SAn8v_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}